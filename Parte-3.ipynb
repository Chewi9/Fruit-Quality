{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c32fe445",
   "metadata": {},
   "source": [
    "# Parte 3 del detector de Fruit-Quality\n",
    "\n",
    "En esta última parte de nuestro detector de fruta, cambiaremos para poder detectar el fondo y de esa forma separar la fruta del fondo, para que no haya ruido que afecte al detector.\n",
    "\n",
    "Para esto usaremos el modelo YOLOv8, el cual nos detectará la fruta que tenemos para así realizar un recorte de esta y eliminar el fondo.\n",
    "\n",
    "Este modelo realiza es un vistazo de la imagen que tenemos, y viéndola nos detecta rápidamente que tipo de fruta es, lo que nos servirá para poder eliminar el fondo.\n",
    "El modelo que tenemos implementado en el proyecto se llama YOLOv8-seg. Este primero detecta la zona dónde tenemos situada la fruta, y posteriormente realiza una segmentación, dibujando el contorno exacto píxel a píxel de la fruta. Esto nos sirve para analizar perfectamente todas las frutas, buscando sólo las imágenes que tiene ya aprendidas, e ignorando las que no son de la misma forma que la que tiene para buscar.\n",
    "\n",
    "En primer lugar cargaremos todos los datos para comenzar a analizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a9a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Función auxiliar para mostrar imágenes en el Notebook\n",
    "def show(img, title=\"\", cmap=None):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    if cmap is None:\n",
    "        # Convierte de BGR (OpenCV) a RGB (Matplotlib)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Cargamos el modelo YOLOv8 preentrenado para segmentación\n",
    "model = YOLO('yolov8n-seg.pt')\n",
    "\n",
    "path = './images/'\n",
    "filename = 'Platano1.jpg' \n",
    "\n",
    "img = cv2.imread(path + filename)\n",
    "\n",
    "if img is None:\n",
    "    print(f\"Error: No se encuentra {filename} en la ruta {path}\")\n",
    "else:\n",
    "    original = img.copy()\n",
    "    show(original, f\"Imagen Original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a439b32f",
   "metadata": {},
   "source": [
    "A continuación, realizaremos la búsqueda de la fruta con YOLOv8-seg para eliminar el fondo y poder continuar usando solo la fruta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ceecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(img, conf=0.4, verbose=False)\n",
    "\n",
    "# Creamos una máscara vacía (todo negro) por defecto\n",
    "mask_fruta = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "max_area = 0\n",
    "\n",
    "# Buscamos la fruta más grande\n",
    "if results[0].masks is not None:\n",
    "    masks = results[0].masks.data.cpu().numpy()\n",
    "    classes = results[0].boxes.cls.cpu().numpy()\n",
    "    names = results[0].names\n",
    "    \n",
    "    for i, class_id in enumerate(classes):\n",
    "        name = names[int(class_id)]\n",
    "        \n",
    "        # Lista de cosas que consideramos \"Fruta\"\n",
    "        if name in ['banana', 'apple', 'pear', 'orange']:\n",
    "            # Redimensionar máscara\n",
    "            mask_raw = masks[i]\n",
    "            mask_resized = cv2.resize(mask_raw, (img.shape[1], img.shape[0]))\n",
    "            current_mask = (mask_resized * 255).astype(np.uint8)\n",
    "            \n",
    "            # Calculamos área\n",
    "            area = cv2.countNonZero(current_mask)\n",
    "            \n",
    "            # LEY DEL MÁS FUERTE: Nos quedamos solo con la fruta más grande\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                mask_fruta = current_mask\n",
    "\n",
    "# Mostramos para confirmar que YOLO ha recortado bien\n",
    "fruta_recortada = cv2.bitwise_and(original, original, mask=mask_fruta)\n",
    "show(fruta_recortada, \"Vista Previa: Fondo eliminado con YOLO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5478e9",
   "metadata": {},
   "source": [
    "Por último realizaremos el análisis de calidad que ya realizábamos en la parte 2 del proyecto, sin ningún cambio relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b281f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suavizado para eliminar ruido\n",
    "blurred = cv2.medianBlur(img, 5)\n",
    "\n",
    "# Detección de zonas oscuras (Histograma)\n",
    "gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# solo calcule los colores DE LA FRUTA, no del fondo.\n",
    "hist = cv2.calcHist([gray], [0], mask_fruta, [256], [0,256])\n",
    "\n",
    "# Buscamos el pico de oscuridad en los primeros 100 valores y sumamos un margen\n",
    "shadow_thresh = np.argmax(hist[:100]) + 5\n",
    "_, shadow_mask = cv2.threshold(gray, shadow_thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Limpiamos ruido en la máscara y la invertimos para que lo blanco sea lo oscuro\n",
    "shadow_mask = cv2.medianBlur(shadow_mask, 9)\n",
    "shadow_mask = cv2.bitwise_not(shadow_mask)\n",
    "\n",
    "# CAMBIO PEQUEÑO 2: Recortamos la sombra para que no detecte el fondo negro como \"defecto\"\n",
    "shadow_mask = cv2.bitwise_and(shadow_mask, shadow_mask, mask=mask_fruta)\n",
    "\n",
    "\n",
    "# Detección por rango de color (HSV)\n",
    "hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "lower_defect = np.array([0, 30, 0])\n",
    "upper_defect = np.array([180, 255, 120])\n",
    "\n",
    "color_mask = cv2.inRange(hsv, lower_defect, upper_defect)\n",
    "\n",
    "# Aseguramos que el color defectuoso esté dentro de la fruta\n",
    "color_mask = cv2.bitwise_and(color_mask, color_mask, mask=mask_fruta)\n",
    "\n",
    "\n",
    "# Detección de bordes\n",
    "edges = cv2.Canny(gray, 40, 120)\n",
    "\n",
    "# Hacemos grandes los bordes para conectarlos mejor\n",
    "edges = cv2.dilate(edges, np.ones((5,5), np.uint8), iterations=2)\n",
    "\n",
    "# Quitamos los bordes del fondo\n",
    "edges = cv2.bitwise_and(edges, edges, mask=mask_fruta)\n",
    "\n",
    "\n",
    "# Solo aceptamos bordes que caigan dentro de la zona oscura\n",
    "defect_edges = cv2.bitwise_and(edges, edges, mask=shadow_mask)\n",
    "\n",
    "# Solo aceptamos defectos de color que caigan dentro de la zona oscura\n",
    "defect_color = cv2.bitwise_and(color_mask, color_mask, mask=shadow_mask)\n",
    "\n",
    "# Combinación\n",
    "combined = cv2.bitwise_or(defect_edges, defect_color)\n",
    "\n",
    "# Si la combinación borra todo, volvemos al color\n",
    "if np.sum(combined) < 20:\n",
    "    print(\"Aviso: Detección combinada muy baja, usando solo color.\")\n",
    "    combined = defect_color\n",
    "\n",
    "# Limpieza final de la máscara combinada\n",
    "combined = cv2.medianBlur(combined, 7)\n",
    "\n",
    "# ULTIMO FILTRO DE SEGURIDAD:\n",
    "combined = cv2.bitwise_and(combined, combined, mask=mask_fruta)\n",
    "\n",
    "# Mostramos resultado final con contornos\n",
    "resultado = original.copy()\n",
    "contornos, _ = cv2.findContours(combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Dibujamos en azul los contornos detectados\n",
    "cv2.drawContours(resultado, contornos, -1, (255, 0, 0), thickness=3)\n",
    "\n",
    "show(resultado, \"Resultado Final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0d13e7",
   "metadata": {},
   "source": [
    "Este código 3 y final no resulta del todo correcto, ya que como venimos comentando durante toda la práctica, el principal problema para esto es la iluminación que tiene la fruta, cuanto más iluminado esté, mejor se detecta la malformación.\n",
    "\n",
    "Con este código podemos incluir bastantes más imágenes a nuestro código, ya que anteriormente solo podían tener fondo blanco, o de lo contrario no lo notaría, pero con este último código, podríamos insertar frutas con cualquier tipo de fondo, ya que si pertenece al modelo de YOLO, se detectará como fruta y podrá pasar a la siguiente parte del algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f991bc",
   "metadata": {},
   "source": [
    "### Prueba para otra imagen tomada con una cámara.\n",
    "\n",
    "A continuación, se probará el modelo de **YOLOv8-seg** con otra imagen para comprobar su correcto funcionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17251964",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './images/'\n",
    "filename = 'Manzana1.jpg' \n",
    "\n",
    "img = cv2.imread(path + filename)\n",
    "\n",
    "if img is None:\n",
    "    print(f\"Error: No se encuentra {filename} en la ruta {path}\")\n",
    "else:\n",
    "    original = img.copy()\n",
    "    show(original, f\"Imagen Original\")\n",
    "\n",
    "\n",
    "\n",
    "results = model(img, conf=0.4, verbose=False)\n",
    "\n",
    "# Creamos una máscara vacía (todo negro) por defecto\n",
    "mask_fruta = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "max_area = 0\n",
    "\n",
    "# Buscamos la fruta más grande\n",
    "if results[0].masks is not None:\n",
    "    masks = results[0].masks.data.cpu().numpy()\n",
    "    classes = results[0].boxes.cls.cpu().numpy()\n",
    "    names = results[0].names\n",
    "    \n",
    "    for i, class_id in enumerate(classes):\n",
    "        name = names[int(class_id)]\n",
    "        \n",
    "        # Lista de cosas que consideramos \"Fruta\"\n",
    "        if name in ['banana', 'apple', 'pear', 'orange']:\n",
    "            # Redimensionar máscara\n",
    "            mask_raw = masks[i]\n",
    "            mask_resized = cv2.resize(mask_raw, (img.shape[1], img.shape[0]))\n",
    "            current_mask = (mask_resized * 255).astype(np.uint8)\n",
    "            \n",
    "            # Calculamos área\n",
    "            area = cv2.countNonZero(current_mask)\n",
    "            \n",
    "            # LEY DEL MÁS FUERTE: Nos quedamos solo con la fruta más grande\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                mask_fruta = current_mask\n",
    "\n",
    "# Mostramos para confirmar que YOLO ha recortado bien\n",
    "fruta_recortada = cv2.bitwise_and(original, original, mask=mask_fruta)\n",
    "show(fruta_recortada, \"Vista Previa: Fondo eliminado con YOLO\")\n",
    "\n",
    "\n",
    "# Suavizado para eliminar ruido\n",
    "blurred = cv2.medianBlur(img, 5)\n",
    "\n",
    "# Detección de zonas oscuras (Histograma)\n",
    "gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# solo calcule los colores DE LA FRUTA, no del fondo.\n",
    "hist = cv2.calcHist([gray], [0], mask_fruta, [256], [0,256])\n",
    "\n",
    "# Buscamos el pico de oscuridad en los primeros 100 valores y sumamos un margen\n",
    "shadow_thresh = np.argmax(hist[:100]) + 5\n",
    "_, shadow_mask = cv2.threshold(gray, shadow_thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Limpiamos ruido en la máscara y la invertimos para que lo blanco sea lo oscuro\n",
    "shadow_mask = cv2.medianBlur(shadow_mask, 9)\n",
    "shadow_mask = cv2.bitwise_not(shadow_mask)\n",
    "\n",
    "# CAMBIO PEQUEÑO 2: Recortamos la sombra para que no detecte el fondo negro como \"defecto\"\n",
    "shadow_mask = cv2.bitwise_and(shadow_mask, shadow_mask, mask=mask_fruta)\n",
    "\n",
    "\n",
    "# Detección por rango de color (HSV)\n",
    "hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "lower_defect = np.array([0, 30, 0])\n",
    "upper_defect = np.array([180, 255, 120])\n",
    "\n",
    "color_mask = cv2.inRange(hsv, lower_defect, upper_defect)\n",
    "\n",
    "# Aseguramos que el color defectuoso esté dentro de la fruta\n",
    "color_mask = cv2.bitwise_and(color_mask, color_mask, mask=mask_fruta)\n",
    "\n",
    "\n",
    "# Detección de bordes\n",
    "edges = cv2.Canny(gray, 40, 120)\n",
    "\n",
    "# Hacemos grandes los bordes para conectarlos mejor\n",
    "edges = cv2.dilate(edges, np.ones((5,5), np.uint8), iterations=2)\n",
    "\n",
    "# Quitamos los bordes del fondo\n",
    "edges = cv2.bitwise_and(edges, edges, mask=mask_fruta)\n",
    "\n",
    "\n",
    "# Solo aceptamos bordes que caigan dentro de la zona oscura\n",
    "defect_edges = cv2.bitwise_and(edges, edges, mask=shadow_mask)\n",
    "\n",
    "# Solo aceptamos defectos de color que caigan dentro de la zona oscura\n",
    "defect_color = cv2.bitwise_and(color_mask, color_mask, mask=shadow_mask)\n",
    "\n",
    "# Combinación\n",
    "combined = cv2.bitwise_or(defect_edges, defect_color)\n",
    "\n",
    "# Si la combinación borra todo, volvemos al color\n",
    "if np.sum(combined) < 20:\n",
    "    print(\"Aviso: Detección combinada muy baja, usando solo color.\")\n",
    "    combined = defect_color\n",
    "\n",
    "# Limpieza final de la máscara combinada\n",
    "combined = cv2.medianBlur(combined, 7)\n",
    "\n",
    "# ULTIMO FILTRO DE SEGURIDAD:\n",
    "combined = cv2.bitwise_and(combined, combined, mask=mask_fruta)\n",
    "\n",
    "# Mostramos resultado final con contornos\n",
    "resultado = original.copy()\n",
    "contornos, _ = cv2.findContours(combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Dibujamos en azul los contornos detectados\n",
    "cv2.drawContours(resultado, contornos, -1, (255, 0, 0), thickness=3)\n",
    "\n",
    "show(resultado, \"Resultado Final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Entorno-Proyecto (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
